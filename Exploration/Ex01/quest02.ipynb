{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgF+sueKGkh7rW9Mz/8MBO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boctory/AIFFEL_quest_cr/blob/main/%08Exploration/Ex01/quest02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBvAKjjsgv8D",
        "outputId": "0aad27b1-0480-41c8-bf86-56e4b67ecc0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 16m 57s]\n",
            "val_accuracy: 0.6818000078201294\n",
            "\n",
            "Best val_accuracy So Far: 0.6818000078201294\n",
            "Total elapsed time: 01h 09m 02s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "64                |48                |initial_filters\n",
            "7                 |7                 |initial_kernel\n",
            "2                 |2                 |n_blocks\n",
            "0.4               |0.4               |dropout\n",
            "0.00053985        |0.0020706         |learning_rate\n",
            "\n",
            "Epoch 1/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 297ms/step - accuracy: 0.3928 - loss: 1.6811 - val_accuracy: 0.4848 - val_loss: 1.5510\n",
            "Epoch 2/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 301ms/step - accuracy: 0.5822 - loss: 1.1647 - val_accuracy: 0.5166 - val_loss: 1.3313\n",
            "Epoch 3/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 293ms/step - accuracy: 0.6507 - loss: 0.9901 - val_accuracy: 0.4998 - val_loss: 1.4707\n",
            "Epoch 4/5\n",
            "\u001b[1m533/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m50s\u001b[0m 295ms/step - accuracy: 0.6869 - loss: 0.8917"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras_tuner import RandomSearch\n",
        "import numpy as np\n",
        "\n",
        "# ResNet 블록 정의\n",
        "def resnet_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True):\n",
        "    shortcut = x\n",
        "\n",
        "    if conv_shortcut:\n",
        "        shortcut = layers.Conv2D(filters, 1, strides=stride)(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Add()([shortcut, x])\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# 하이퍼파라미터 튜닝을 위한 모델 빌더\n",
        "def build_model(hp):\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "\n",
        "    # 초기 컨볼루션 레이어\n",
        "    x = layers.Conv2D(\n",
        "        hp.Int('initial_filters', 32, 64, step=16),  # 1. Unit size 튜닝\n",
        "        kernel_size=hp.Choice('initial_kernel', [3, 5, 7]),  # 2. Kernel size 튜닝\n",
        "        strides=2,\n",
        "        padding='same'\n",
        "    )(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "    # ResNet 블록\n",
        "    for i in range(hp.Int('n_blocks', 2, 4)):  # 3. 레이어 수 튜닝\n",
        "        x = resnet_block(x, 64 * (2 ** i))\n",
        "\n",
        "    # 글로벌 풀링\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Dropout\n",
        "    dropout_rate = hp.Float('dropout', 0.2, 0.5, step=0.1)  # 4. Dropout rate 튜닝\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # 출력 레이어\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    # 옵티마이저 및 학습률 튜닝\n",
        "    learning_rate = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')  # 5. Learning rate 튜닝\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# 검증 세트 분리\n",
        "val_size = 5000\n",
        "x_val = x_train[-val_size:]\n",
        "y_val = y_train[-val_size:]\n",
        "x_train = x_train[:-val_size]\n",
        "y_train = y_train[:-val_size]\n",
        "\n",
        "# GPU 확인\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# 하이퍼파라미터 튜닝 실행\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    directory='cifar10_resnet_tuning',\n",
        "    project_name='cifar10_resnet'\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=3)]\n",
        ")\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"\\n최적의 하이퍼파라미터:\")\n",
        "print(f\"Initial filters: {best_hps.get('initial_filters')}\")\n",
        "print(f\"Initial kernel size: {best_hps.get('initial_kernel')}\")\n",
        "print(f\"Number of ResNet blocks: {best_hps.get('n_blocks')}\")\n",
        "print(f\"Dropout rate: {best_hps.get('dropout')}\")\n",
        "print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n",
        "\n",
        "# 최적의 모델로 최종 평가\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "evaluation = best_model.evaluate(x_test, y_test)\n",
        "print(f\"\\n테스트 세트 성능:\")\n",
        "print(f\"Loss: {evaluation[0]:.4f}\")\n",
        "print(f\"Accuracy: {evaluation[1]:.4f}\")\n",
        "\n",
        "# 학습 곡선 시각화\n",
        "best_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=5)],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet\n",
        "장점\n",
        "성능 관련\n",
        "\t•\t매우 깊은 네트워크(수백 개의 레이어)를 효과적으로 학습할 수 있음\n",
        "\t•\t이미지넷과 같은 벤치마크 데이터셋에서 최고 수준의 성능을 달성\n",
        "\t•\t학습 속도가 빠르고 수렴이 더 잘됨\n",
        "구조적 이점\n",
        "\t•\tSkip connection을 통해 그래디언트 소실 문제를 해결\n",
        "\t•\t초기 레이어가 마지막 레이어만큼 빠르게 학습 가능\n",
        "\t•\t전이학습에 매우 적합하여 적은 데이터로도 좋은 성능 달성 가능\n",
        "\n",
        "단점\n",
        "리소스 관련\n",
        "\t•\t깊은 네트워크로 인한 높은 계산 비용과 긴 학습 시간 소요\n",
        "\t•\t메모리 사용량이 많음\n",
        "기술적 한계\n",
        "\t•\t모델의 복잡성으로 인한 해석의 어려움\n",
        "\t•\t데이터셋이 작을 경우 과적합 위험이 있음\n",
        "\t•\t모바일 기기나 임베디드 시스템과 같은 제한된 환경에서 사용이 어려움"
      ],
      "metadata": {
        "id": "ol7MX1UGu12c"
      }
    }
  ]
}